<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Big Data Compute on Community Over Code Europe</title>
    <link>https://eu.communityovercode.org/track/big-data-compute/</link>
    <description>Recent content in Big Data Compute on Community Over Code Europe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://eu.communityovercode.org/track/big-data-compute/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Anatomy of reading Apache Parquet files (from the Apache Impala perspective)</title>
      <link>https://eu.communityovercode.org/sessions/2024/anatomy-parquet-files/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/anatomy-parquet-files/</guid>
      <description>Reading file formats efficiently is a crucial part of big data systems - in selective scans data is often only big before hitting the first filter and becomes manageable during the rest of the processing. The talk describes this early stage of query execution in Apache Impala, from reading the bytes of Parquet files on the filesystem to applying predicates and runtime filters on individual rows.
Apache Impala is a distributed massively parallel analytic query engine written in C++ and Java.</description>
    </item>
    
    <item>
      <title>Hive-Iceberg - Breaking the Ice: A Closer Look at Hive-Iceberg</title>
      <link>https://eu.communityovercode.org/sessions/2024/hive-iceberg-breaking-the-ice-a-closer-look-at-hive-iceberg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/hive-iceberg-breaking-the-ice-a-closer-look-at-hive-iceberg/</guid>
      <description>The session will start by covering the latest developments made in hive-iceberg and followed by an overview of the work done to seamlessly integrate Hive and Iceberg. Along with a deep dive into the various cool features supported by hive-iceberg , ranging from statistics, branching tagging, compactions, concurrency and much more.</description>
    </item>
    
    <item>
      <title>Obtain, Distribute and Use Temporary Credentials Automatically in Apache Spark and Apache Flink</title>
      <link>https://eu.communityovercode.org/sessions/2024/obtain-distribute-and-use-temporary-credentials-automatically-in-apache-spark-and-apache-flink/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/obtain-distribute-and-use-temporary-credentials-automatically-in-apache-spark-and-apache-flink/</guid>
      <description>The importance of security is increasing sharply nowadays which must be reflected in open source projects. Apache Spark and Apache Flink are two of the most widely used Big Data frameworks which can be used for data processing. Both of them offer dozens of external service connectors where authentication plays an essential role. Each external system does its authentication in a different way but a common framework can be provided to ease the life of developers.</description>
    </item>
    
    <item>
      <title>Optimal Approaches for Real-Time Machine Learning with Apache Spark on Kubernetes.</title>
      <link>https://eu.communityovercode.org/sessions/2024/optimal-approaches-for-real-time-machine-learning-with-apache-spark-on-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/optimal-approaches-for-real-time-machine-learning-with-apache-spark-on-kubernetes/</guid>
      <description>As machine learning (ML) models increasingly become integral components of modern applications, there is a growing need to deploy them in real-time environments. Apache Spark is a popular open-source framework for large-scale data processing that supports ML tasks, while Kubernetes provides a powerful platform for container orchestration and deployment. However, combining Spark and Kubernetes poses significant challenges, especially when it comes to achieving low latency and high scalability. In this session, we explore optimal approaches for real-time ML with Apache Spark on Kubernetes, including best practices and strategies for efficient model training, deployment, and serving.</description>
    </item>
    
    <item>
      <title>Orchestrating Scalable Data Pipelines with Apache Toree, YuniKorn, Spark, and Airflow</title>
      <link>https://eu.communityovercode.org/sessions/2024/orchestrating-scalable-data-pipelines-with-apache-toree-yunikorn-spark-and-airflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/orchestrating-scalable-data-pipelines-with-apache-toree-yunikorn-spark-and-airflow/</guid>
      <description>This session explores the integrated use of Apache Toree, YuniKorn, Spark, and Airflow to create efficient, scalable data pipelines. We will start by discussing how Apache Toree provides an interactive analysis environment with Spark via Jupyter Notebook. Then, we’ll discuss using Apache YuniKorn to manage and schedule these computational resources, ensuring system efficiency. Central to our talk, we’ll delve into the role of Apache Spark in large-scale data processing, highlighting its integration with Toree and YuniKorn.</description>
    </item>
    
    <item>
      <title>Simplifying Data Processing with Apache Flink SQL</title>
      <link>https://eu.communityovercode.org/sessions/2024/simplifying-data-processing-with-apache-flink-sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/simplifying-data-processing-with-apache-flink-sql/</guid>
      <description>Apache Flink is a powerful open-source stream processing framework that supports unified batch and streaming processing. With its SQL support, Flink has become even more accessible to data analysts and developers who are familiar with SQL.
In this talk, we will provide a short introduction to Apache Flink and explain how you can leverage SQL under the hood. We will cover some of the SQL-specific features of Flink, such as dynamic tables, streaming SQL and support for stateful operations like windowing and pattern recognition.</description>
    </item>
    
    <item>
      <title>Understanding stream table duality using Kafka, Flink SQL and Debezium format</title>
      <link>https://eu.communityovercode.org/sessions/2024/understanding-stream-table-duality-using-kafka-flink-sql-and-debezium-format/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/understanding-stream-table-duality-using-kafka-flink-sql-and-debezium-format/</guid>
      <description>Kafka Streams, ksqlDB or Flink SQL are popular processing engines that enable us to run SQL queries on top of streaming data. Isn&amp;rsquo;t it fascinating that we can run SQL queries on top of streaming data as if they were relational tables, or convert a table into a stream of changelog events? This is known as the stream-table duality.
In this talk we will try to understand how it works under the hood using Flink SQL, Kafka connector with Debezium JSON/Avro format.</description>
    </item>
    
  </channel>
</rss>
