<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Search on Community Over Code Europe</title>
    <link>https://eu.communityovercode.org/track/search/</link>
    <description>Recent content in Search on Community Over Code Europe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://eu.communityovercode.org/track/search/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hybrid Search with Apache Solr</title>
      <link>https://eu.communityovercode.org/sessions/2024/hybrid-search-with-apache-solr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/hybrid-search-with-apache-solr/</guid>
      <description>Vector-based search gained incredible popularity in the last few years: Large Language Models fine-tuned for sentence similarity proved to be quite effective in encoding text to vectors and representing some of the semantics of sentences in a numerical form.
These vectors can be used to run a K-nearest neighbour search and look for documents/paragraphs close to the query in a n-dimensional vector space, effectively mimicking a similarity search in the semantic space (Apache Solr KNN Query Parser).</description>
    </item>
    
    <item>
      <title>Navigating Challenges and Enhancing Performance of LLM based Applications</title>
      <link>https://eu.communityovercode.org/sessions/2024/navigating-challenges-and-enhancing-performance-of-llm-based-applications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/navigating-challenges-and-enhancing-performance-of-llm-based-applications/</guid>
      <description>Retrieval-Augmented Generation (RAG) is probably one of the most popular implementations of LLMs that integrates retrieval and generation models, augmenting AI&amp;rsquo;s understanding of text and improving response accuracy through an information database.
This approach tackles the limitations of traditional generation models by fusing retrieval mechanisms, and enriching outputs with contextual depth and external knowledge.
Evaluating applications using LLMs, such as RAG, is pivotal for confidence and improvement, yet faces challenges like subjectiveness with respect to domain-specific suitability.</description>
    </item>
    
    <item>
      <title>Solr Eclipse - Zomato&#39;s Journey to 64 Million Search Queries a Day</title>
      <link>https://eu.communityovercode.org/sessions/2024/solr-eclipse-zomato-s-journey-to-64-million-search-queries-a-day/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/solr-eclipse-zomato-s-journey-to-64-million-search-queries-a-day/</guid>
      <description>Zomato is the Indian market leader for restaurant aggregation and food delivery.
This is a story of how Zomato leverages the power of Apache Solr at scale, some of the problems we faced and how we tackled them to reach where we are now.
Starting with just one Solr instance serving 1000 queries a day with 10K restaurants, to building and shipping a massive, first in class, search server with the capability of seamlessly searching 100 Million restaurant catalogues (SKUs), 800K+ restaurants and 50K+ unique dishes in 13 different languages at 64 Million search queries a day.</description>
    </item>
    
    <item>
      <title>Vector Search at Uber</title>
      <link>https://eu.communityovercode.org/sessions/2024/vector-search-at-uber/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eu.communityovercode.org/sessions/2024/vector-search-at-uber/</guid>
      <description>Vector Search has been regarded as a revolution for Search and Information Retrieval since the breakthrough with BERT and GPT in 2018. There has been an ever growing interest from both academia and industry in using machine learning models and vector search to leverage all sorts of content beyond the lexical features, including images, events, contextual semantics and so on.
At Uber, we added the Vector Search support by leveraging Apache Lucene to our Search platform, and empower multiple business-critical use cases, such as Semantic Search and Gen AI support.</description>
    </item>
    
  </channel>
</rss>
